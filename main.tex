\documentclass{article}

\usepackage[english]{babel}

\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{forest}
\usepackage{amsthm}
\usepackage{cancel}
\usepackage{tabularray}
\usepackage{xfrac}
\UseTblrLibrary{booktabs} % pro pěknější čáry
\UseTblrLibrary{siunitx}  % pro čísla s oddělovačem
\usepackage{xcolor}
\usepackage{tabularray}
\usepackage{xurl} % Enables flexible URL line breaking
\usepackage{hyperref} % For clickable links
\UseTblrLibrary{diagbox}
\usepackage{nicematrix}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\title{treti clanek}
\author{Adam Ulrich}
\date{November 2025}

\begin{document}

\maketitle

\section{Introduction}
\begin{itemize}
    \item V citacich ukazeme ze je potreba resit missing data
    \item pripomeneme strom a $c(k)$
    \item popis se ze to deje casto v datech a ZMINIT CLANEK BURDA NOVAK
\end{itemize}

Let an HS-Tree be built from $n$ data points. Then the expected value of the depth of a data point in the tree is given by
\begin{lemma}[Recurrence for $c(n)$]
The expected depth satisfies
\begin{align}
c(n) &=
\begin{cases}
0, & n = 0, \\
1 + \dfrac{1 + \sum_{k=0}^{n-1} \binom{n}{k} \cdot c(k)}{2^n - 1}, & n \ge 1.
\end{cases}
\label{eq:cprime}
\end{align}
Moreover, it can equivalently be expressed as
\begin{align}
c(n) = \frac{\sum_{k=0}^{n}\binom{n}{k}\,\bigl(1 + c(k)\bigr)}{2^n}.
\label{eq:cn-alternative}
\end{align}
\end{lemma}

\begin{proof}
Starting from
\[
c'(n) = 1 + \frac{1 + \sum_{k=0}^{n-1} \binom{n}{k}\,c(k)}{2^n - 1},
\]
rewrite the extra term $1$ as $\binom{n}{0}\cdot 1$ and extend the sum:
\[
1 + \sum_{k=0}^{n-1} \binom{n}{k}\,c(k)
= \sum_{k=0}^{n} \binom{n}{k}\,\bigl(1 + c(k)\bigr).
\]
Normalize by the full binomial sum $\sum_{j=0}^{n}\binom{n}{j}=2^n$:
\[
c(n) = \frac{\sum_{k=0}^{n}\binom{n}{k}\,\bigl(1 + c(k)\bigr)}{2^n}.
\]
\end{proof}


\section{Model Extension for Missing Features}
In this section, we aim to derive a parameter that adjusts the expected depth when missing features occur, ensuring consistency with the original model.

\subsection{Tree Structures for Initial Partitioning}
We consider an infinite HS-tree that recursively partitions its space. Computing the expected depth of such a tree (or forest) reduces to evaluating probabilities over all possible splits. At each level, data points are randomly assigned left or right with equal probability, analogous to coin flips:
\[
\text{Heads} \rightarrow \text{left}, \quad \text{Tails} \rightarrow \text{right}.
\]
Each split increases depth by one.

In previous work, we introduced the function \( c(n) \), representing the expected depth given \( n \) coins at the root. We now extend this model to account for missing features. Missing outcomes are denoted by \( R \) (edge), assuming
\[
\Pr(H) = \Pr(T) = \Pr(R) = \tfrac{1}{3}.
\]
An \( R \)-coin propagates to both branches, altering the first split but not subsequent ones, which follow the original \( c(n) \) dynamics.

To approximate this effect, we define an adjustment term \( a_{r,k} \), where \( r \) is the number of \( R \)-coins and \( k \) the total coins. This term compensates for the initial distortion so that, beyond the first level, the tree behaves as if no missing data were present. Table~\ref{tab:stromecek_batch3_1R} illustrates all possible first-split configurations under this extended model; deeper levels are irrelevant once the approximation is applied.

\subsection{Example: One Missing Feature, Batch Size 3}

Consider a case with one missing feature and a batch size of $3$. Table~\ref{tab:stromecek_batch3_1R} shows all possible first-level splits. Using these configurations, we compute the expected depth $c(3)$, adding the adjustment parameter $a$ for the first split; subsequent levels follow the usual $c(k)$ for the size of the left branch (by symmetry, WLOG we take the left branch).

\begin{table}[ht]
\centering
\caption{All possible one-depth trees with three features and exactly one missing.}
\label{tab:stromecek_batch3_1R}
\begin{tabular}{cccc}
\toprule
\begin{forest}
[RHH [RHH] [R]]
\end{forest} &
\begin{forest}
[RHT [RH] [RT]]
\end{forest} &
\begin{forest}
[RTH [RH] [RT]]
\end{forest} &
\begin{forest}
[RTT [R] [RTT]]
\end{forest} \\
\begin{forest}
[HRH [RHH] [R]]
\end{forest} &
\begin{forest}
[HRT [RH] [RT]]
\end{forest} &
\begin{forest}
[TRH [RH] [RT]]
\end{forest} &
\begin{forest}
[TRT [R] [RTT]]
\end{forest} \\
\begin{forest}
[HHR [RHH] [R]]
\end{forest} &
\begin{forest}
[HTR [RH] [RT]]
\end{forest} &
\begin{forest}
[THR [RH] [RT]]
\end{forest} &
\begin{forest}
[TTR [R] [RTT]]
\end{forest} \\
\bottomrule
\end{tabular}
\end{table}

\begin{enumerate}
    \item Compute the expected depth by weighting all configurations:
    \[
    c(3) = \frac{1}{12}\Biggl(
        \frac{3!}{1!2!0!}(a + c(3)) +
        \frac{3!}{1!0!2!}(a + c(1)) +
        \frac{3!}{1!1!1!}(a + c(2))
    \Biggr).
    \]

    \item Isolate $a$:
    \[
    a_{1,3} = c(3) - \Bigl( \tfrac14 c(3) + \tfrac14 c(1) + \tfrac12 c(2) \Bigr).
    \]
\end{enumerate}

\subsection{Generalization}


From this, the adjustment term $a_{r,k}$ satisfies:
\begin{align}
c(k)
&= \frac{\sum_{i=0}^{k-r} \binom{k-r}{i}\,\bigl(a_{r,k} + c(r+i)\bigr)}
        {\sum_{j=0}^{k-r} \binom{k-r}{j}} \\[6pt]
&= \frac{a_{r,k}\sum_{i=0}^{k-r}\binom{k-r}{i} + \sum_{i=0}^{k-r}\binom{k-r}{i}\,c(r+i)}
        {\sum_{j=0}^{k-r}\binom{k-r}{j}} \\[6pt]
&= a_{r,k} + \frac{\sum_{i=0}^{k-r}\binom{k-r}{i}\,c(r+i)}{2^{\,k-r}}.
\end{align}
Denote the subtrahend by $c(r,k)$.
\begin{definition}
\label{definition:c(r,k)}
For two integers $r,k$, with $0 \le r \le k$, we define
\begin{align}
    c(r,k) = \frac{\sum_{i=0}^{k-r} \binom{k-r}{i} \cdot c(r+i)}{2^{\,k-r}}.
\end{align}
\end{definition}

We can compute a few sample values for Table~\ref{tab:cprime_values} (for $c(n)$) and Table~\ref{tab:crk_values} (for $c(r,k)$).
\begin{table}[htp]
\centering
\caption{Sample values of $c(n)$ with decimal and fractional approximations}
\begin{tblr}{
  colspec = {r S[table-format=2.5] S},
  column{2-3} = {mode=math},
  row{1} = {guard,font=\bfseries},
}
{n} & {Decimal} & {Fraction} \\
\midrule
0  & 0        & \sfrac{0}{1} \\
1  & 2        & \sfrac{2}{1} \\
2  & 2.667    & \sfrac{8}{3} \\
3  & 3.14286  & \sfrac{22}{7} \\
4  & 3.505    & \sfrac{368}{105} \\
5  & 3.794    & \sfrac{2\,470}{651} \\
6  & 4.0348   & \sfrac{7\,880}{1\,953} \\
7  & 4.240    & \sfrac{150\,266}{35\,433} \\
8  & 4.4210   & \sfrac{13\,315\,424}{3\,011\,805} \\
9  & 4.581    & \sfrac{2\,350\,261\,538}{513\,010\,785} \\
10 & 4.725    & \sfrac{1\,777\,792\,792}{376\,207\,909} \\
11 & 4.856    & \sfrac{340\,013\,628\,538}{70\,008\,871\,793} \\
\vdots & \vdots & \vdots \\
1024 & 11.335    & \vdots \\
2048 & 12.3331   & \vdots \\
4096 & 13.3329   & \vdots \\
8192 & 14.3328   & \vdots \\
%\bottomrule
\end{tblr}
\label{tab:cprime_values}
\end{table}

\begin{table}[ht]
\centering
\caption{$c(r,k)$ values}
\label{tab:crk_values}

\begin{tblr}{
  colspec = {c c c c c c c},
  hline{2} = {1pt},
  vline{2} = {1pt},
  row{1} = {font=\bfseries},
  row{2-Z} = {rowsep=6pt},
  column{1} = {font=\bfseries},
}

% Horní levá buňka: r (řádky), k (sloupce)
\diagbox{r}{k}
& 0 & 1 & 2 & 3 & 4 & 5 \\

0 &
$\mathbf{\frac{0}{1}}$ &
$\frac{1}{1}$ &
$\frac{5}{3}$ &
$\frac{15}{7}$ &
$\frac{263}{105}$ &
$\frac{1819}{651}$ \\

1 &
-- &
$\mathbf{\frac{2}{1}}$ &
$\frac{7}{3}$ &
$\frac{55}{21}$ &
$\frac{43}{15}$ &
$\frac{10037}{3255}$ \\

2 &
-- & -- &
$\mathbf{\frac{8}{3}}$ &
$\frac{61}{21}$ &
$\frac{109}{35}$ &
$\frac{3581}{1085}$ \\

3 &
-- & -- & -- &
$\mathbf{\frac{22}{7}}$ &
$\frac{349}{105}$ &
$\frac{3783}{1085}$ \\

4 &
-- & -- & -- & -- &
$\mathbf{\frac{368}{105}}$ &
$\frac{1697}{465}$ \\

5 &
-- & -- & -- & -- & -- &
$\mathbf{\frac{2470}{651}}$ \\

\end{tblr}
\end{table}


\subsection{Interesting consequences of the definitions}

The mapping $c(r,k)$ satisfies the following boundary identities:

\begin{lemma}
\label{lemma:crk}
The following relations hold for all $k \ge 0$:
\begin{enumerate}
    \item $c(k,k) = c(k)$,
    \item $c(0,k) = c(k) - 1$, for all $k > 0$.
\end{enumerate}
\end{lemma}

\begin{proof}

\begin{align*}
c(k,k)&= \frac{\sum_{i'=0}^{0} \binom{0}{i'}\,c(k+i')}{2^{0}}
     = \binom{0}{0}\,c(k)
     = c(k).\\
c(k) &= 1+\frac{\sum_{k=0}^{n} \binom{n}{k} c(k)}{2^n} =1+c(0,k).
\end{align*}

\end{proof}

\subsection{Analogy for the provided lemma}
\textcolor{red}{TODO: TOTO TROCHU VYLEPSIT (honza)}

We define $c(r,k)$ as the expected depth \textbf{after the first partition}, under the assumption that no further missing features occur. This isolates the effect of incomplete data at level one; subsequent splits follow the pure model described by $c(k)$.

To illustrate, consider the case with one missing feature and batch size four. Averaging over all first-level configurations leads to:
\[
c(1,4) = \binom{3}{2}c(3) + \binom{3}{1}c(2) + \binom{3}{3}c(4) + \binom{3}{0}c(1),
\]
which generalizes naturally to the recurrence:
\[
c(r,k) = \frac{c(r,k-1) + c(r+1,k)}{2}.
\]

This formulation mirrors the pure model but introduces an averaging step to capture the uncertainty introduced by missing features.

\subsubsection*{Key Insight}
\textbf{$c(r,k)$} represents the expected depth beyond the first split, assuming that from level two onward the process is complete (no missing data).

Consequently:
\begin{itemize}
    \item $c(k)$ (or $c(n)$ in earlier sections) is the expected depth in the pure model.
    \item $c(r,k)$ adjusts only for the first level; deeper levels behave as in the pure case.
    \item When $r = 0$, the first split is already accounted for, so we subtract one step from $c(k)$.
\end{itemize}

This yields

\begin{itemize}
    \item $c(k,k) = c(k)$: If all features are missing, the first split adds no information; depth remains as in the pure model.
    \item $c(0,k) = c(k) - 1$ for $k > 0$: With no missing features, the remaining depth equals the pure model depth minus the initial step.
\end{itemize}

This explanation makes the analogy explicit:
\begin{itemize}
    \item $c(k)$ is the original expected depth.
    \item $c(r,k)$ is the adjusted depth after accounting for missingness at level one.
    \item The subtraction of $1$ reflects that the first partition has already been counted.
\end{itemize}

\section{Defining \(c(r,k)\) independently of \(c(k)\)}
While \(c(r,k)\) can be computed directly from the values \(c(k)\) as illustrated 
above, this approach is unnecessarily cumbersome once one recalls the structure 
of \(c(k)\).  We therefore seek an intrinsic characterisation of \(c(r,k)\) that 
does not rely on \(c(k)\).

\subsection{\( c(r, k) \) as a solution to a system of linear equations}

\begin{theorem}
\label{theorem:3equations_of_crk}
For integers \(k>r\ge 0\), the function \(c(r,k)\) satisfies:
\begin{align}
    c(0,0) &= 0, \label{eq:c00}\\
    c(k,k)-c(0,k) &= 1, \label{eq:ckk-c0k}\\
    c(r,k) &= \frac{c(r,k-1) + c(r+1,k)}{2}. \label{eq:crk_to_proof}
\end{align}
\end{theorem}

\begin{proof}
Equalities~\eqref{eq:c00} and~\eqref{eq:ckk-c0k} follow directly from 
Lemma~\ref{lemma:crk}.  
To prove~\eqref{eq:crk_to_proof}, we expand the right–hand side using the 
definition of \(c(r,k)\) accordingly:
\begin{multline*}
\frac{c(r,k-1)+c(r+1,k)}{2}=\\
=\frac{1}{2}\left(\frac{\sum_{i=0}^{k-1-r}\binom{k-1-r}{i}c(r+i)}{2^{k-1-r}}+\frac{\sum_{i=0}^{k-r-1}\binom{k-r-1}{i}c(r+1+i)}{2^{k-r-1}}\right)=\\
 =\frac{1}{2^{k-r}}\left(\textstyle\binom{k-1-r}{0}\,c(r)
 +\sum_{i=1}^{k-r-1}\left(\binom{k-1-r}{i}+\binom{k-r-1}{i-1}\right)c(r+i)
 +\binom{k-r-1}{k-r-1}\,c(k)\right) =\\
=\frac{1}{2^{k-r}}\left(\binom{k-r}{0}\,c(r)+\sum_{i=1}^{k-r-1}\,\binom{k-r}{i}\,c(r+i)+\binom{k-r}{k-r}\,c(k)\right)=\\
=\frac{1}{2^{k-r}}\sum_{j=0}^{k-r}c(r+j)\binom{k-r}{j}=c(r,k).
\end{multline*}

\end{proof}


\subsection{Uniqueness of the coefficients}

In this subsection we show that the values \(c(r,k)\) are uniquely determined.

% CESKA VERZE
% Mějme sadu rovnic
% \begin{align*}
%     c_{0,0}&=0\\
%     c_{k,k}-c_{0,k}&=1\\
%     c_{r,k}&=\frac{c_{r,k-1}+c_{r+1,k}}{2}
% \end{align*}
% Tato soustava má jediné řešení, dokážu:
% $c_{0,0}=0$, to je jednoznačně dané.
% Pak indukcí: $c_{r,k-1}\rightarrow c_{r,k}$
% Pod podmínkou $0\le r\le k$, $r,k\in \mathbb{N}$ přepíšu soustavu do tvaru:
% \begin{align*}
%     2c_{r,k}-c_{r+1,k}&=c_{r,k-1}\\
%     c_{k,k}-c_{0,k}&=1
% \end{align*}
% A zapíšu do matice

% \[
% \left[
% \begin{array}{ccccc|c}
%     2 & -1 & 0 & \cdots & 0 & c_{0,k-1} \\
%     0 & 2 & -1 & \cdots & 0 & c_{1,k-1} \\
%     \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
%     0 & 0 & \cdots & 2 & -1 & c_{k-1,k-1} \\
%     -1 & 0 & \cdots & 0 & 1 & 1
% \end{array}
% \right]
% \]

% Snadno z Laplaceova rozvoje podle posledního řádku plyne, že determint matice soustavy je nenulový, resp.
% \begin{align*}
%   \begin{vmatrix}
%     2 & -1 & 0 & \cdots & 0& 0 \\
%     0 & 2 & -1 & \cdots & 0& 0 \\
%     0 & 0 & 2 & \cdots & 0& 0 \\
%     \vdots & \vdots & \vdots & \ddots & \vdots &\vdots\\
%     0 & 0 & 0&\cdots & 2 & -1  \\
%     -1 & 0 & 0&\cdots & 0 & 1 
%   \end{vmatrix}&=2^k-1\\
% \end{align*}

% Determinant matice $D$ je nenulový, protože:
% Přímo z definice jediné nenulové permutace jsou:
% \begin{enumerate}
%     \item $k+1$ řádků od $2$ do $k$, dává $2^k$
%     \item permutace $(-1)^{k+1}$
%     Ale musime ještě správné znaménko, takže počet inverzí je počet prvků před jedničkou, tj. $k$. Pak počet permutací je $2^k+(-1)^{2k+1}=2^k-1$
% \end{enumerate}
% Tím pádem přímo z definice je determinant nenulový $\rightarrow$ soustava má 1 řešení.
% Známe tedy $c_{r,k-1}$ pro $0,....k-1$.
% Z toho tedy jednoznačně určíme $c(r,k)$ pro $r=0,....k$.
Let us consider the system of equations:
\[
\begin{aligned}
    c_{0,0} &= 0,\\
    c_{k,k} - c_{0,k} &= 1,\\
    c_{r,k} &= \frac{c_{r,k-1} + c_{r+1,k}}{2}.
\end{aligned}
\]

This system admits a unique solution. I will prove this as follows:

First, \(c_{0,0} = 0\), which is uniquely determined.  
Then, by induction, we have \(c_{r,k-1} \rightarrow c_{r,k}\).

Under the condition \(0 \le r \le k,\; r,k \in \mathbb{N}\), the system can be rewritten as:
\[
\begin{aligned}
    2c_{r,k} - c_{r+1,k} &= c_{r,k-1},\\
    c_{k,k} - c_{0,k} &= 1.
\end{aligned}
\]

We now express it in matrix form:
\[
\left(
\begin{NiceArray}{ccccc|c}
    2 & -1 & 0 & \Cdots & 0 & c_{0,k-1} \\
    0 & 2 & -1 & \Cdots & 0 & c_{1,k-1} \\
    \Vdots & \Vdots & \Vdots & \Ddots & \Vdots & \Vdots \\
    0 & 0 & \Cdots & 2 & -1 & c_{k-1,k-1} \\
    -1 & 0 & \Cdots & 0 & 1 & 1
\end{NiceArray}
\right)
\]


It follows easily from the Laplace expansion along the last row that the determinant of the system matrix is nonzero, namely:
\[
\begin{aligned}
  \begin{vmatrix}
    2 & -1 & 0 & \cdots & 0 & 0 \\
    0 & 2 & -1 & \cdots & 0 & 0 \\
    0 & 0 & 2 & \cdots & 0 & 0 \\
    \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
    0 & 0 & 0 & \cdots & 2 & -1  \\
    -1 & 0 & 0 & \cdots & 0 & 1 
  \end{vmatrix} &= 2^k - 1.
\end{aligned}
\]


\begin{remark}
It is also possible to find an inverse matrix.

\textcolor{red}{HELP VUBEC NEVIM CO TADY}

\[
B_2 =
\begin{pmatrix}
2 & 1 & 1 \\
1 & 2 & 2 \\
2 & 1 & 4
\end{pmatrix},
\qquad
B_1 =
\begin{pmatrix}
2 & -1 & 0 \\
0 & 2 & -1 \\
-1 & 0 & 1
\end{pmatrix}.
\]

Compute:
\[
C = B_2 \cdot B_1 =
\begin{pmatrix}
2 & 1 & 1 \\
1 & 2 & 2 \\
2 & 1 & 4
\end{pmatrix}
\begin{pmatrix}
2 & -1 & 0 \\
0 & 2 & -1 \\
-1 & 0 & 1
\end{pmatrix}
=
\begin{pmatrix}
3 & 0 & 0 \\
0 & 3 & 0 \\
0 & 0 & 3
\end{pmatrix}
= 3I.
\]

Multiplying by \(\frac{1}{3}\) gives:
\[
\frac{1}{3} C = I,
\]
which shows that \(B_2 = 3 B_1^{-1}\), and hence \(B_1^{-1} = \frac{1}{3} B_2\).


\subsection{Deriving the subsequent column from its predecessor}

We now express each value $c(r,k)$, for $0 \le r \le k$, solely in terms of the
preceding column $c(r,k-1)$.

\begin{enumerate}
    \item Iterating the $k$–recurrence.

Starting from
\[
c(k+1,n)=2c(k,n)-c(k,n-1),
\]
we expand successively:
\begin{align*}
c(1,n) &= 2c(0,n)-c(0,n-1),\\
c(2,n) &= 2c(1,n)-c(1,n-1)
       = 2^{2}c(0,n)-2c(0,n-1)-c(1,n-1),\\
c(3,n) &= 2c(2,n)-c(2,n-1)
       = 2^{3}c(0,n)-2^{2}c(0,n-1)-2c(1,n-1)-c(2,n-1),
\end{align*}
and so on.  
By induction, for every $k\ge1$,
\begin{align}
c(k,n)
 = 2^{k}c(0,n)
   -\sum_{j=0}^{k-1}2^{\,k-1-j}\,c(j,n-1).
\label{eq:ckn_iterated}
\end{align}
The case $k=0$ is trivial: $c(0,n)=c(0,n)$.

\item Closing the formula using the boundary condition.
Setting $k=n$ in \eqref{eq:ckn_iterated} and using the boundary relation
$c(n,n)=c(0,n)+1$, we obtain
\[
2^{n}c(0,n)-\sum_{j=0}^{n-1}2^{\,n-1-j}\,c(j,n-1)=c(0,n)+1.
\]
Solving for $c(0,n)$ gives
\begin{align}
c(0,n)
 = \frac{
        1 + \displaystyle\sum_{j=0}^{n-1}2^{\,n-1-j}c(j,n-1)
      }{2^{n}-1}.
\label{eq:c0n_closed}
\end{align}

\item Column transformation.

Define the weighted sum
\[
S_n := \sum_{j=0}^{n-1}2^{\,n-1-j}\,c(j,n-1).
\]
Then by \eqref{eq:c0n_closed} and \eqref{eq:ckn_iterated},
\begin{align*}
c(0,n) &= \frac{1+S_n}{2^{n}-1},\\[2pt]
c(k,n) &= 2^{k}c(0,n)
         -\sum_{j=0}^{k-1}2^{\,k-1-j}\,c(j,n-1),
         \qquad k=1,\dots,n.
\end{align*}

\item Example.

For $n=2$ let
\[
\bigl(c(0,2),c(1,2),c(2,2)\bigr)
   =\left(\frac{5}{3},\frac{7}{3},\frac{8}{3}\right).
\]
Then
\[
S_3
 = 2^{2}c(0,2)+2^{1}c(1,2)+2^{0}c(2,2)
 = 14,
\]
and hence
\[
c(0,3)=\frac{1+S_3}{2^{3}-1}=\frac{15}{7}.
\]
The remaining values follow from the recursion:
\begin{align*}
c(1,3)
 &=2c(0,3)-c(0,2)
 =\frac{55}{21},\\[2pt]
c(2,3)
 &=4c(0,3)-\bigl(2c(0,2)+c(1,2)\bigr)
 =\frac{61}{21},\\[2pt]
c(3,3)
 &=8c(0,3)-\bigl(4c(0,2)+2c(1,2)+c(2,2)\bigr)
 =\frac{22}{7}.
\end{align*}
Thus the column for $n=3$ is
\[
\bigl(c(0,3),c(1,3),c(2,3),c(3,3)\bigr)
=\left(\frac{15}{7},\frac{55}{21},\frac{61}{21},\frac{22}{7}\right).
\]
\end{enumerate}

\end{remark}



% stara ceska verze:
% \paragraph{Cíl.}
% Chceme vyjádřit \(c(k,n)\) (pro \(0\le k\le n\)) jen pomocí sloupce \(n{-}1\),
% tj. hodnot \(c(j,n{-}1)\) pro \(0\le j\le n{-}1\).

% \paragraph{Krok 1: rozvinutí rekurence v~$k$.}

% \paragraph{Iterační rozvinutí rekurence.}
% Vycházíme z~rekurence
% \[
% c(k{+}1,n)=2c(k,n)-c(k,n{-}1).
% \]

% Postupným dosazováním dostaneme:

% \[
% \begin{aligned}
% c(1,n) &= 2c(0,n)-c(0,n-1), \\
% c(2,n) &= 2c(1,n)-c(1,n-1) \\
%        &= 2\!\bigl(2c(0,n)-c(0,n-1)\bigr)-c(1,n-1) \\
%        &= 2^{2}c(0,n)-2c(0,n-1)-c(1,n-1), \\
% c(3,n) &= 2c(2,n)-c(2,n-1) \\
%        &= 2\!\left(2^{2}c(0,n)-2c(0,n-1)-c(1,n-1)\right)-c(2,n-1) \\
%        &= 2^{3}c(0,n)-2^{2}c(0,n-1)-2c(1,n-1)-c(2,n-1), \\
% &\qquad\vdots \\
% c(k,n) &= 2^{k}c(0,n)
%         \;-\;\Bigl(2^{k-1}c(0,n-1)+2^{k-2}c(1,n-1)+\cdots+2^{0}c(k-1,n-1)\Bigr).
% \end{aligned}
% \]

% Kompaktně:
% \[
% \boxed{
% c(k,n)
% =
% 2^{k}c(0,n)
% -\sum_{j=0}^{k-1}2^{\,k-1-j}\,c(j,n-1).
% }
% \]


% Z \(c(k{+}1,n)=2c(k,n)-c(k,n{-}1)\) iterací dostaneme
% \[
% c(k,n)=2^{k}\,c(0,n)\;-\;\sum_{j=0}^{k-1} 2^{\,k-1-j}\,c(j,n-1),\qquad k\ge 1,
% \]
% a triviálně \(c(0,n)=c(0,n)\).

% \paragraph{Krok 2: uzavření pomocí okraje.}
% Pro \(k=n\) a okraj \(c(n,n)=c(0,n)+1\) platí
% \[
% 2^{n}c(0,n)-\sum_{j=0}^{n-1}2^{\,n-1-j}c(j,n-1)=c(0,n)+1,
% \]
% tedy
% \[
% c(0,n)=\frac{1+\displaystyle\sum_{j=0}^{n-1}2^{\,n-1-j}\,c(j,n-1)}{2^{n}-1}.
% \]

% Nejprve spočti vážený součet
% \[
% S_n:=\sum_{j=0}^{n-1}2^{\,n-1-j}\,c(j,n-1).
% \]
% Pak
% \[
% \boxed{\;
% c(0,n)=\frac{1+S_n}{2^{n}-1},\qquad
% c(k,n)=2^{k}c(0,n)-\sum_{j=0}^{k-1}2^{\,k-1-j}\,c(j,n-1)\ \ (k=1,\dots,n).
% \;}
% \]

% \paragraph{Mini-příklad}
% \begin{enumerate}
%     \item Máme sloupec pro \(n=2\):
%     \[
%     (c(0,2),c(1,2),c(2,2))=\left(\frac{5}{3},\frac{7}{3},\frac{8}{3}\right).
%     \]

%     \item Spočítáme vážený součet
%     \[
%     S_3
%     =2^2c(0,2)+2^1c(1,2)+2^0c(2,2)
%     =\frac{20}{3}+\frac{14}{3}+\frac{8}{3}
%     =14.
%     \]

%     \item Získáme
%     \[
%     c(0,3)=\frac{1+S_3}{2^3-1}
%     =\frac{15}{7}.
%     \]

%     \item Další hodnoty dopočítáme vzorcem
%     \[
%     c(k,3)=2^k c(0,3)-\sum_{j=0}^{k-1}2^{k-1-j}c(j,2).
%     \]

%     \begin{enumerate}
%         \item Pro \(k=1\):
%         \[
%         c(1,3)=2c(0,3)-c(0,2)
%         =\frac{30}{7}-\frac{5}{3}
%         =\frac{55}{21}.
%         \]

%         \item Pro \(k=2\):
%         \[
%         c(2,3)=4c(0,3)-\left(2c(0,2)+c(1,2)\right)
%         =\frac{60}{7}-\frac{17}{3}
%         =\frac{61}{21}.
%         \]

%         \item Pro \(k=3\):
%         \[
%         c(3,3)=8c(0,3)-\left(4c(0,2)+2c(1,2)+c(2,2)\right)
%         =\frac{120}{7}-14
%         =\frac{22}{7}.
%         \]
%     \end{enumerate}

%     \item Výsledný sloupec pro \(n=3\) je
%     \[
%     \bigl(c(0,3),c(1,3),c(2,3),c(3,3)\bigr)
%     =
%     \left(\frac{15}{7},\frac{55}{21},\frac{61}{21},\frac{22}{7}\right).
%     \]
% \end{enumerate}


\section{Alternative definitions}

\subsection{Theory}
\url{https://physics.bme.hu/sites/physics.bme.hu/files/users/BMETE15AF53_kov/Kreyszig%20-%20Introductory%20Functional%20Analysis%20with%20Applications%20(1).pdf} . 

The definitions used in this section follow the terminology of Kreyszig~\cite{kreyszig1991introductory}.


% \begin{definition}[The sequence space $\ell^{p}$]
% \label{kreyszig1.2-3}
% Let $p \ge 1$ be a fixed real number.
% The space $\ell^{p}$ consists of all sequences 
% \begin{align}
% x = (\xi_j) = (\xi_1, \xi_2, \ldots)    
% \end{align}
% of real or complex numbers for which the series
% \begin{align}
% |\xi_1|^{p} + |\xi_2|^{p} + \cdots    
% \end{align}
% is convergent.  
% Equivalently,
% \begin{align}
% \sum_{j=1}^{\infty} |\xi_j|^{p} < \infty,
% \qquad (p \ge 1\ \text{fixed})\label{eq:l2iflesstheninfty}.
% \end{align}

% The metric on $\ell^{p}$ is given by
% \[
% d(x,y)
%  = \left( 
%         \sum_{j=1}^{\infty} |\xi_j - \eta_j|^{p}
%    \right)^{1/p},
% \]
% where $y = (\eta_j)$ and the series $\sum |\eta_j|^{p}$ is also finite.

% \end{definition}
% The space $\ell^{p}$ introduced earlier admits a natural norm structure,
% which turns it into a fundamental example of a Banach space.  


% \begin{definition}[Norm on $\ell^{p}$]
% The norm on $\ell^{p}$ is defined by

% \begin{align}
% \|x\| = \left( \sum_{j=1}^{\infty} |\xi_j|^{p} \right)^{1/p}\label{eq:lpnorm},
% \end{align}
% where $x = (\xi_j)$ is a sequence in $\ell^{p}$.

% This norm induces the metric introduced previously in 1.2--3, since
% \[
% d(x,y) = \|x - y\|
%        = \left( \sum_{j=1}^{\infty} |\xi_j - \eta_j|^{p} \right)^{1/p},
% \]
% for $y = (\eta_j)$.  
% Kreyszig also established the completeness of $\ell^{p}$ with respect to this metric (see section 1.5--4. in \cite{kreyszig1991introductory}).
% \end{definition}

% The concept of an inner product is central to the study of Hilbert spaces.
% We follow the exposition of Kreyszig~\cite[Section~3.1]{kreyszig1991introductory}.

% \begin{definition}[Inner product space and Hilbert space]
% Let $X$ be a vector space over a scalar field $\mathbb{K}$ (either $\mathbb{R}$ or $\mathbb{C}$).
% An \emph{inner product} on $X$ is a mapping 
% \[
% \langle \cdot , \cdot \rangle : X \times X \to \mathbb{K},
% \]
% which associates to each pair of vectors $x,y \in X$ a scalar $\langle x , y\rangle$
% and satisfies the following properties for all vectors $x,y,z \in X$ and all scalars $\alpha$:

% \begin{align*}
% \text{(IP1)}\quad &\langle x+y, z \rangle = \langle x, z \rangle + \langle y, z \rangle, \\
% \text{(IP2)}\quad &\langle \alpha x, y \rangle = \alpha \langle x, y \rangle, \\
% \text{(IP3)}\quad &\langle x, y \rangle = \overline{\langle y, x \rangle}, \\
% \text{(IP4)}\quad &\langle x, x \rangle \ge 0, 
% \qquad 
% \langle x, x \rangle = 0 \ \Longleftrightarrow\ x = 0.
% \end{align*}

% A vector space equipped with an inner product is called an \emph{inner product space}
% (or pre-Hilbert space).  
% If the space is complete with respect to the metric induced by the inner product,
% it is called a \emph{Hilbert space}.  
% The corresponding norm is given by
% \begin{equation}
% \|x\| = \sqrt{\langle x, x \rangle}.
% \end{equation}

% Further details can be found in Kreyszig~\cite[Section~3.1]{kreyszig1991introductory}.
% \end{definition}

% Precisely, from now on, we shall mainly operate in the Hilbert sequence
% space $\ell^{2}$. This space provides a concrete and well–understood model of a
% Hilbert space and is a standard setting for the analysis of operators on
% infinite-dimensional spaces. We follow the presentation of 
% Kreyszig~\cite[Section~3.1--6]{kreyszig1991introductory}.

\begin{definition}[Hilbert sequence space $\ell^{2}$]
The space $\ell^{2}$ consists of all sequences 
$\mathsf{x} = (\xi_j) = (\xi_1, \xi_2, \ldots)$ of real or complex numbers for which
\begin{align}
\sum_{j=1}^{\infty} |\xi_j|^{2} < \infty \label{eq:l2iflesstheninfty}
\end{align}
that is, the series of squares is convergent.  

It is equipped with the inner product
\[
\langle x , y \rangle 
  = \sum_{j=1}^{\infty} \xi_j \,\overline{\eta_j},
\]
where $x = (\xi_j)$ and $y = (\eta_j)$ belong to $\ell^{2}$.  
The convergence of this series follows from the Cauchy--Schwarz inequality and
the assumption that $x,y\in \ell^{2}$.  

The induced norm is given by
\[
\|x\| = \langle x , x \rangle^{1/2}
      = \left( \sum_{j=1}^{\infty} |\xi_j|^{2} \right)^{1/2}.
\]

The completeness of $\ell^{2}$ with respect to this norm was established in Kreyszig's
Section~1.5--4, so $\ell^{2}$ forms a prototypical example of a Hilbert space.
\end{definition}


\subsection{Defining $c(r,k)$ in Hilbert space}

In the sequel we work entirely inside the Hilbert sequence space $\ell^{2}$, 
so vectors are understood as infinite sequences.  
In particular, a polynomial will be represented not by its symbolic form
$a_0 + a_1 x + \cdots + a_n x^n$, but by the corresponding coefficient 
sequence $(a_0, a_1, \ldots, a_n, 0, 0, 0, \dots)$, whose zeros extend to infinity.  
This identification is standard when polynomials are viewed as elements of a 
Hilbert space of sequences. However, we shall stick to the symbolic form notation.

\begin{definition}[Multiplication vector $v_c$]
Define the vector
\[
v_c = \bigl(0,\, 1,\,-\tfrac{1}{3},\,\tfrac{1}{7},\,\ldots,\,\tfrac{(-1)^{i+1}}{2^i-1},\,\ldots\bigr).
\]
\end{definition}

\begin{lemma}
    Multiplication vector $v_c$ satisfies all conditions for it to be part of $\ell^{2}$.
\end{lemma}

\begin{proof}
We recall the condition for item to be in $\ell^{2}$:
\begin{align}
\sum_{j=1}^{\infty} |\xi_j|^{2} < \infty. \label{eq:l2iflesstheninfty}
\end{align}
Indeed, for $\xi_j = \dfrac{(-1)^{j+1}}{2^j-1}$ we have
\[
|\xi_j|^{2} = \frac{1}{(2^j-1)^2} \le \frac{1}{4^j}.
\]
Thus,
\[
\sum_{j=1}^{\infty} |\xi_j|^{2} \le \sum_{j=1}^{\infty} \frac{1}{4^j},
\]
which is a convergent geometric series with ratio $\tfrac{1}{4}$. Therefore, $v_c \in \ell^{2}$.
\end{proof}

\begin{definition}[Infinite polynomial $P_{r,k}$]
For $k=0,1\dots$ and $r=0,1 \dots k$ we define the polynomial $P_{r,k}(x)$
\[
P_{r,k}(x) = (1+2x)^{r}(1+x)^{\,k-r}.
\]
In the Hilbert sequence space $\ell^{2}$ we identify $P_{r,n}$ with its
coefficient sequence
\[
P_{r,k} \;\equiv\; (\alpha_0, \alpha_1, \alpha_2, \ldots),
\]
where $\alpha_j$ is the coefficient of $x^{j}$ and all remaining entries are
$0$.  
Thus each $P_{r,k}$ is viewed as an element of $\ell^{2}$ and inner products
such as $\langle P_{r,k}, v^{(k)} \rangle$ are understood in the standard 
Hilbert space sense. Table \ref{tab:prkcoefficients} shows several examples of $P_{r,k}$ coefficeints.
\end{definition}

\begin{table}[h!]
\label{tab:prkcoefficients}
\centering
\begin{tabular}{c|cccc}
$(r,k)$ & $\alpha_0$ & $\alpha_1$ & $\alpha_2$ & $\alpha_3$ \\
\hline
(0,0) & 1 & 0 & 0 & 0 \\
(0,1) & 1 & 1 & 0 & 0 \\
(1,1) & 1 & 2 & 0 & 0 \\
(0,2) & 1 & 2 & 1 & 0 \\
(1,2) & 1 & 3 & 2 & 0 \\
(2,2) & 1 & 4 & 4 & 0 \\
(0,3) & 1 & 3 & 3 & 1 \\
(1,3) & 1 & 4 & 5 & 2 \\
(2,3) & 1 & 5 & 8 & 4 \\
(3,3) & 1 & 6 & 12 & 8 \\
\end{tabular}
\caption{Prk coefficients}
\end{table}

We now show that the sequence $P_{r,k}$ belongs to the space $\ell^{2}$ by 
verifying that it satisfies the defining condition~\eqref{eq:l2iflesstheninfty}.

\begin{proof}
By Definition \eqref{eq:l2iflesstheninfty} we identify the polynomial
$P_{r,k}(x)$ with its coefficient sequence
\[
P_{r,k} \;\equiv\; (\alpha_0, \alpha_1, \ldots, \alpha_k, 0, 0, \dots).
\]
In particular, $\alpha_j = 0$ for all $j > k$.  
Therefore the series in~\eqref{eq:l2iflesstheninfty} reduces to a finite sum,
\[
\sum_{j=0}^{\infty} |\alpha_j|^{2}
  = \sum_{j=0}^{k} |\alpha_j|^{2} < \infty.
\]
Hence $P_{r,k}$ satisfies the defining condition~\eqref{eq:l2iflesstheninfty},
and we conclude that $P_{r,k} \in \ell^{2}$.
\end{proof}

We can directly show that the polynomials $P_{r,k}$ satisfy the same three–term
recurrence as $c(r,k)$:
\begin{align}
2P_{r,k}(x) = P_{r,k-1}(x) + P_{r+1,k}(x), \qquad 0 \le r < k\label{eq:2prk=prk+prk},    
\end{align}


where $P_{r,k}(x) = (1+2x)^{r}(1+x)^{\,k-r}$.

\begin{proof}
By definition,
\[
P_{r,k-1}(x) = (1+2x)^{r}(1+x)^{k-1-r},
\qquad
P_{r+1,k}(x) = (1+2x)^{r+1}(1+x)^{k-1-r}.
\]
Hence
\begin{align*}
P_{r,k-1}(x) + P_{r+1,k}(x)
&= (1+2x)^{r}(1+x)^{k-1-r}\bigl(1 + (1+2x)\bigr) \\
&= (1+2x)^{r}(1+x)^{k-1-r}(2+2x) \\
&= 2(1+2x)^{r}(1+x)^{k-r} \\
&= 2P_{r,k}(x),
\end{align*}
which is the claimed identity.
\end{proof}


\begin{theorem}
For integers $0 \le r \le k$, the coefficient $c(r,k)$ can be expressed as the
inner product of the multiplication vector $v_c$ and the polynomial $P_{r,k}$ in
the Hilbert sequence space $\ell^{2}$:
\[
c(r,k) = \langle v_c, P_{r,k} \rangle.
\]
\end{theorem}

% TODO: TOTO CELE SMAZAT
% Řekneme že Prk vychází z pascala ale je to trochu říznuté:


% Klasický binomický rozvoj dává řádky Pascalova trojúhelníku:
% \[
% (1+x)^n=\sum_{j=0}^n \binom{n}{j}x^j.
% \]
% Pro \(n=4\) (což je matice 5x5) dostaneme koeficienty \([1,4,6,4,1]\).
% To je \emph{první (horní) řádek} naší matice \(5\times5\). Další řádky se u nás ale liší

% \[
% \begin{bmatrix}
% \textbf{1} & \textbf{4} & \textbf{6} & \textbf{4} & \textbf{1} \\
% 1 & 5 & 9 & 7 & 2 \\
% 1 & 6 & 13 & 12 & 4 \\
% 1 & 7 & 18 & 19 & 8 \\
% 1 & 8 & 24 & 32 & 16 \\
% \end{bmatrix}
% \]

% Pro úplnost Tabulka \ref{tab:pascal_matrices} obsahuje predchozi matice.

% \begin{table}[h]
% \centering
% \renewcommand{\arraystretch}{1.2}
% \setlength{\tabcolsep}{8pt}
% \begin{tabular}{c c c c}
% \toprule
% $1\times 1$ & $2\times 2$ & $3\times 3$ & $4\times 4$ \\
% \midrule
% $\begin{bmatrix}
% 1
% \end{bmatrix}$
% &
% $\begin{bmatrix}
% 1 & 1 \\
% 1 & 2
% \end{bmatrix}$
% &
% $\begin{bmatrix}
% 1 & 2 & 1 \\
% 1 & 3 & 2 \\
% 1 & 4 & 4
% \end{bmatrix}$
% &
% $\begin{bmatrix}
% 1 & 3 & 3 & 1 \\
% 1 & 4 & 5 & 2 \\
% 1 & 5 & 8 & 4 \\
% 1 & 6 & 12 & 8
% \end{bmatrix}$ \\
% \bottomrule
% \end{tabular}
% \caption{První čtyři matice (od $1\times1$ do $4\times4$).}
% \label{tab:pascal_matrices}
% \end{table}

% Tedy řádek s $r$ kroky typu $R$ je reprezentován polynomem
% \[
% P_{r,n}(x)=(1+2x)^r(1+x)^{\,n-r}.
% \]

% \paragraph{Mini–příklad.}
% Pro $n=4$ a $r=1$ máme
% \[
% P_{1,4}(x)=(1+2x)(1+x)^3.
% \]
% Rozviňme $(1+x)^3=1+3x+3x^2+x^3$, takže
% \[
% P_{1,4}(x)=(1+2x)(1+3x+3x^2+x^3).
% \]
% Po roznásobení dostáváme
% \[
% P_{1,4}(x)=1+5x+9x^2+7x^3+2x^4.
% \]


% \noindent
% Zatimco klasický pascalovský řádek pro $n=4$ je
% \[
% (1+x)^4=1+4x+6x^2+4x^3+x^4.
% \]


% \paragraph{Zavedeme váhový vektor.}
% Definuj
% \[
% \mathbf{v}^{(k)}=\biggl(0,\;\frac{(-1)^{0}}{2^1-1},\;\frac{(-1)^{1}}{2^2-1},\;\dots,\;\frac{(-1)^{k-1}}{2^k-1}\biggr)
% =\Bigl(0,\;1,\;-\tfrac13,\;\tfrac17,\;-\tfrac1{15},\;\dots\frac{(-1)^{k-1}}{2^k-1}\Bigr).
% \]


% \paragraph{Příklad 1: \(c(0,3)\).}
% První řádek (\(r=0\)) matice \(4\times 4\) je
% \[
% \mathbf{M}_0 = (1,\,3,\,3,\,1).
% \]

% Respektive použijeme když použijeme přímo polynom $P_{r,k}$:
% \begin{align*}
% P_{r,n}(x)=(1+2x)^r(1+x)^{\,n-r}\\
% P_{0,3}(x) = (1+x)^3 = x^{3} + 3x^{2} + 3x + 1.    
% \end{align*}

% Mějme Euklidovský prostor. Skalární součin s váhovým vektorem \(\mathbf{v}^{(3)}\) dává
% \[
% c(0,3)=\langle\mathbf{M}_0, \mathbf{v}^{(3)}\rangle
% = 3\cdot 1 + 3\cdot\!\Bigl(-\tfrac{1}{3}\Bigr) + 1\cdot \tfrac{1}{7}
% = \tfrac{15}{7}.
% \]

% Z toho lze tedy videt
% \begin{theorem}
% Pro $k>r\ge0$ zobrazení $c(r,k)$ splňuje následující

% \[
% c(r,k) = \langle (0,\bigg(\frac{(-1)^{j-1}}{2^j-1}\bigg)^{\infty}_{j=1}), P_{r,k} \rangle.
% \]
% \end{theorem}




With $c(r,k)$ calculated this way, let us prove it satisfies all three equations proposed in Theorem \ref{theorem:3equations_of_crk}.



\begin{proof}
Let us prove the equations \eqref{eq:c00}, \eqref{eq:ckk-c0k},\eqref{eq:crk_to_proof} resectively.
\begin{enumerate}
    \item $c(0,0) = \langle v_c, P_{0,0}\rangle = (0,\,1,\,-\tfrac{1}{3},\,\tfrac{1}{7},\ldots) \cdot (1,0,0,\ldots) = 0$.

\item $c(k,k)-c(0,k) = 1$:

Recall that
\[
c(r,k) = \langle v_c, P_{r,k} \rangle,
\]
where $v_c = (0,\,1,\,-\tfrac{1}{3},\,\tfrac{1}{7},\ldots,\tfrac{(-1)^{m+1}}{2^m-1},\ldots)$ and
\[
P_{r,k}(x) = (1+2x)^r(1+x)^{k-r}.
\]

For $r=k$, we have
\[
P_{k,k}(x) = (1+2x)^k = \sum_{m=0}^{k} \binom{k}{m} (2x)^m,
\]
so its coefficient sequence is $(1,\,2\binom{k}{1},\,2^2\binom{k}{2},\ldots,2^k\binom{k}{k},0,\ldots)$.

Thus
\[
c(k,k) = \sum_{m=1}^{k} \binom{k}{m} 2^m \cdot \frac{(-1)^{m+1}}{2^m-1}.
\]

Similarly, for $r=0$,
\[
P_{0,k}(x) = (1+x)^k = \sum_{m=0}^{k} \binom{k}{m} x^m,
\]
so
\[
c(0,k) = \sum_{m=1}^{k} \binom{k}{m} \cdot \frac{(-1)^{m+1}}{2^m-1}.
\]

Subtracting gives
\[
c(k,k) - c(0,k) = \sum_{m=1}^{k} \binom{k}{m} (-1)^{m+1} \left( \frac{2^m}{2^m-1} - \frac{1}{2^m-1} \right)
= \sum_{m=1}^{k} \binom{k}{m} (-1)^{m+1} = 1,
\]
by the binomial identity $\sum_{m=0}^{k} \binom{k}{m} (-1)^m = 0$.


\item $c(r,k) = \frac{c(r,k-1) + c(r+1,k)}{2}$:

By definition,
\[
c(r,k) = \langle v_c, P_{r,k} \rangle,
\]
where $P_{r,k}(x) = (1+2x)^r(1+x)^{k-r}$.

From the polynomial identity \eqref{eq:2prk=prk+prk}:
\[
P_{r,k-1}(x) + P_{r+1,k}(x) = 2P_{r,k}(x).
\]

Using linearity of the inner product:
\begin{align*}
\langle v_c, P_{r,k-1}\rangle + \langle v_c, P_{r+1,k}\rangle
&= \langle v_c, 2P_{r,k}\rangle \\
&= 2\langle v_c, P_{r,k}\rangle.
\end{align*}

Thus,
\[
c(r,k-1) + c(r+1,k) = 2c(r,k),
\]
and dividing by $2$ gives
\[
c(r,k) = \frac{c(r,k-1) + c(r+1,k)}{2}.
\]

    
\end{enumerate}
\end{proof}
    


% Hence
% \[
% c(r,k) = \langle \sum q, P_{r,k} \rangle = 
% \]
% \[
% = \langle (0,\bigg(\frac{(-1)^{j-1}}{2^j-1}\bigg)^{\infty}_{j=1}), P_{r,k} \rangle.
% \]

% Pak se suma da vytknout
% \[
% c(r,k) = \sum\langle  q, P_{r,k} \rangle,
% \]


% Od tohoto je to uz jen krucek k $b_{r,k}$
\subsection{Corollaries}

As a corollary, a finite vector $v_c$ can be interchanged for an infinite sequence $(q_j)$ in $\ell^{2}$, enabling methods that require infinite-dimensional representations.

\begin{definition}[Alternative geometric vector $q_j$]
\label{definition:vjqj}
For each integer $j\ge 1$ we define the geometric vector
\[
q_j = \bigl(0,\,2^{-j},\,-2^{-2j},\,2^{-3j},\,-2^{-4j},\ldots\bigr),
\]
so that $(q_j)_0 = 0$ and
\[
(q_j)_m = (-1)^{m-1}2^{-jm},\qquad m\ge 1.
\]
\end{definition}


We now show that the vector $q_j$ belongs to the space $\ell^{p}$ by 
verifying that it satisfies the defining condition~\eqref{eq:l2iflesstheninfty}.



\begin{lemma}
\label{prop:sumq}
The series of vectors $\sum_{j=1}^{\infty} q(j)$ converges in $\ell^{2}$ and its
sum is given componentwise by
\[
\sum_{j=1}^{\infty} q(j)
 = v_c,
\]
then $c(r,k)$ can be expressed as the inner product
\begin{align*}
c(r,k) = \left\langle v_c,\, P_{r,k} \right\rangle
 = \left\langle \sum_{j=1}^{\infty} q(j),\, P_{r,k} \right\rangle.
\end{align*}
And we can even reorder the sum
\begin{align*}
c(r,k)
 = \left\langle \sum_{j=1}^{\infty} q(j),\, P_{r,k} \right\rangle
 = \sum_{j=1}^{\infty} \langle q(j),\, P_{r,k} \rangle.
\end{align*}
\end{lemma}

\begin{proof}
To prove the first equation,
By Definition~\ref{definition:vjqj} we have
\[
q(j) = \bigl(0,\,2^{-j},\,-2^{-2j},\,2^{-3j},\,-2^{-4j},\ldots\bigr),
\]
so for every $m \ge 1$,
\[
q(j)_m = (-1)^{m-1} 2^{-jm}.
\]
Fix $m \ge 1$. Then
\[
\sum_{j=1}^{\infty} q(j)_m
 = \sum_{j=1}^{\infty} (-1)^{m-1} 2^{-jm}
 = (-1)^{m-1} \sum_{j=1}^{\infty} (2^{-m})^{j}.
\]
The inner sum is a geometric series with first term $a = 2^{-m}$ and ratio
$r = 2^{-m}$, where $0 < 2^{-m} < 1$. Hence
\[
\sum_{j=1}^{\infty} (2^{-m})^{j}
 = \frac{2^{-m}}{1-2^{-m}}=\frac{(-1)^{m-1}}{2^{m}-1} ,
\]
and therefore
\[
\sum_{j=1}^{\infty} q(j)= v_c.
\]
%STARY PROOF PRES GEOMETRICKOU S
% To prove the first equation, we recall the formula for a geometric series
% \[
% S_n = a\,\frac{1-r^n}{1-r},
% \qquad
% S_\infty = \frac{a}{1-r}
% \quad\text{for } |r|<1.
% \]

% Next, we write out the first few rows of the vectors $q(j)$:
% \begin{align*}
% q(1) &= (0,2^{-1},-2^{-2},\cdots,(-1)^{k+1}2^{-k},\cdots)\\
% q(2) &= (0,2^{-2},-2^{-4},\cdots,(-1)^{k+1}2^{-2k},\cdots)
% \end{align*}
% and so on.  

% For each fixed column index $k \ge 1$ we now look at the $k$-th entries
% of these rows.
% which satisfies $0<2^{-k}<1$.

% Therefore, by the geometric series formula,
% \begin{align}
% &S_n = a\frac{1-r^n}{1-r}\\
%       &S_\infty = (-1)^{k+1}2^{-k}\frac{1-(\frac{(-1)^{k+1}2^{-2k}}{(-1)^{k+1}2^{-k}})^\infty}{1-(\frac{(-1)^{k+1}2^{-2k}}{(-1)^{k+1}2^{-k}})} = (-1)^{k+1}2^{-k}\frac{1-(2^{-k})^\infty}{1-(2^{-k})}=\\
%       &=\frac{(-1)^{k-1}}{2^k-1} = \sum_{j=1}^{\infty}q(j)
% \end{align}
% Since each $q(j)$ has zero in the first component, the zeroth component of the
% sum is also $0$.  This yields
% \[
% \sum_{j=1}^{\infty} q(j)
%  = v_c,
% \]
% which is the desired result.

To prove the second equation, we have already proven that
\[
c(r,k)
 = \left\langle \sum_{j=1}^{\infty} q(j),\, P_{r,k} \right\rangle.
\]
And since we have proven that $\sum_{j=1}^{\infty} q(j) = v_c$ and also $c(r,k) = \left\langle  v_c, P_{r,k} \right\rangle$, we write
\[
c(r,k) = \left\langle  v_c, P_{r,k} \right\rangle
 = \left\langle \sum_{j=1}^{\infty} q(j),\, P_{r,k} \right\rangle.
\]

To prove the third, reordered equation
\[
c(r,k)
 = \Big\langle \sum_{j=1}^{\infty} q(j),\, P_{r,k} \Big\rangle
 = \sum_{j=1}^{\infty} \langle q(j),\, P_{r,k} \rangle,
\]
we use the linearity of the inner product in its first argument.  
By axioms (IP1)–(IP2) in Kreyszig~\cite[p.~129]{kreyszig1991introductory},
\[
\langle x+y,\, z\rangle = \langle x, z\rangle + \langle y, z\rangle,
\qquad
\langle \alpha x,\, z\rangle = \alpha\,\langle x, z\rangle.
\]

Since $P_{r,k}$ has only finitely many nonzero components, the inner product in $\ell^{2}$ is linear for finite sums. For infinite sums, this property extends by continuity because $\ell^{2}$ is complete: if the series converges in the $\ell^{2}$ norm, then
\[
\Big\langle \sum_{j=1}^{\infty} q(j),\, P_{r,k}\Big\rangle
= \sum_{j=1}^{\infty} \langle q(j),\, P_{r,k}\rangle.
\]
\end{proof}

\subsection{Notable candidate definitions}

\begin{lemma}
For integers $0 \le r < k$ and $n>0$, the inner product admits the representation
\begin{align}
\langle q(j), P_{r,k} \rangle = \Bigl[\,1 - (1-2^{1-j})^{r}(1-2^{-j})^{\,k-r}\Bigr].\label{eq:crk=<qj,prk>}
\end{align}


\end{lemma}

\begin{proof}
We treat $P_{r,k}$ as a coefficient vector in $\ell^2$, but note that its polynomial form is
\[
P_{r,k}(x) = (1+2x)^r(1+x)^{k-r}.
\]


We first expand $P_{r,k}$.
\begin{align*}
P_{r,k}(x) = (1+2x)^r(1+x)^{k-r}\\
P_{r,k}(x) = \alpha_0+\alpha_1x+\alpha_2x^2+\dots+\alpha_kx^k
\end{align*}
Evaluating $P_{r,k}$ at $-2^{-j}$ yields
\begin{align}
    P_{r,k}(-2^{-j}) = \alpha_0+\alpha_1(-2^{-j})+\alpha_2(-2^{-j})^2+\dots+\alpha_k(-2^{-j})^k
\end{align}
Then we perform a scalar multiplication $\langle q(j),P_{r,k} \rangle$.
\begin{multline}
\bigl\langle (0,\,2^{-j},\,-2^{-2j},\,2^{-3j},\dots),\;(\alpha_0,\alpha_1,\dots,\alpha_k,0,0,\dots)\bigr\rangle=\\
= \alpha_0\cdot0+\alpha_1\cdot 2^{-j} + \alpha_2\cdot (-2^{-2j}) + \alpha_3\cdot 2^{-3j} + \dots + \alpha_k\cdot(-1)^{k-1}2^{-kj} + 0+ \dots =\\
=\alpha_0-(\alpha_0+\alpha_1\cdot (-2^{-j}) + \alpha_2\cdot (+2^{-2j}) + \alpha_3\cdot 2^{-3j} + \dots + \alpha_k\cdot(-2^{-j})^k + 0+ \dots)
\end{multline}
The subtrahend is exactly equal to $P_{r,k}(-2^{-j})$ as we have shown above and $\alpha_0 =1$, yielding
$$\bigl\langle (0,\,2^{-j},\,-2^{-2j},\,2^{-3j},\dots),\;(\alpha_0,\alpha_1,\dots,\alpha_k,0,0,\dots)\bigr\rangle=1-P_{r,k}(-2^{-j}).$$
We conclude:
\[
\langle q(j), P_{r,k}\rangle = 1 - (1-2^{1-j})^r(1-2^{-j})^{k-r}.
\]

\paragraph{Note:}Although $P_{r,k}$ is treated as a vector of coefficients, we allow ourselves to evaluate the polynomial for convenience, as this substitution reveals the closed form.
\end{proof}

\begin{theorem}
For integers $0 \le r < k$ and $n>0$, the $c(r,k)$ admits the representation
    \begin{align*}
    c(r,k)=\sum_{j=1}^\infty(1 - (1-2^{1-j})^r(1-2^{-j})^{k-r})
    \end{align*}
\end{theorem}

\begin{proof}
    We shall prove this using the above proven equation \eqref{eq:crk=<qj,prk>}. Since 
    \[
c(r,k) = \left\langle  v_c, P_{r,k} \right\rangle
 = \sum_{j=1}^{\infty} \left\langle q(j),\, P_{r,k} \right\rangle,
\] and 
\begin{align}
\langle q(j), P_{r,k} \rangle = \Bigl[\,1 - (1-2^{1-j})^{r}(1-2^{-j})^{\,k-r}\Bigr],
\end{align}
then 
\begin{align*}
    c(r,k)=\sum_{j=1}^\infty(1 - (1-2^{1-j})^r(1-2^{-j})^{k-r})
\end{align*}


\end{proof}

\section{Approximation of $c(r,k)$ function}

In what follows, we introduce a quantity that measures the change of
\(c(r,k)\) along the \(r\)-direction.  
It will play a central role in understanding how the values of \(c(r,k)\)
propagate across each column \(k\) and may lead to approximation.

\begin{definition}[\(b(r,k)\)]
For integers \(k \ge 0\) and \(1 \le r \le k\) we define
\[
b(r,k) = c(r,k) - c(r-1,k).
\]
\end{definition}

\begin{lemma} For integers \(1 \le r \le k\), $b(r,k)$ satisfies the following equations 
\label{lemma:brk}
\begin{align}
    \sum_{j=1}^{k}b(j,k)&=1\label{eq:b_rkis1},\\
    \frac{1}{2}b(r+1,k)+\frac{1}{2}b(r,k-1)&=b(r,k)\label{eq:0.5b+0.5b}
\end{align}
\end{lemma}

\begin{proof}
We now prove that these two equation hold.
\begin{enumerate}
    \item For the first equation:
    \[
    \sum_{j=1}^{k} b(j,k) = 1.
    \]
    By definition, $b(j,k) = c(j,k) - c(j-1,k)$, so the sum telescopes:
    \[
    \sum_{j=1}^{k} \bigl(c(j,k) - c(j-1,k)\bigr) = c(k,k) - c(0,k).
    \]
    Since $c(k,k) - c(0,k) =1$ (see \eqref{eq:ckk-c0k}), the result follows:
    \[
    \sum_{j=1}^{k} b(j,k) = 1.
    \]

    \item For the second equation:
    \[
    \frac{1}{2} b(r+1,k) + \frac{1}{2} b(r,k-1) = b(r,k).
    \]
    Using $b(r,k) = c(r,k) - c(r-1,k)$ and the recurrence
    \[
    2c(r,k) = c(r,k-1) + c(r+1,k),
    \]
    we compute:
    \begin{align*}
    \frac{1}{2} b(r+1,k) + \frac{1}{2} b(r,k-1)
    &= \frac{1}{2}\bigl(c(r+1,k) - c(r,k)\bigr)
     + \frac{1}{2}\bigl(c(r,k-1) - c(r-1,k-1)\bigr) \\
    &= \frac{1}{2}\bigl(c(r+1,k) + c(r,k-1)\bigr)
     - \frac{1}{2}\bigl(c(r,k) + c(r-1,k-1)\bigr) \\
    &= c(r,k) - c(r-1,k) \\
    &= b(r,k).
    \end{align*}
    This proves the second identity.
\end{enumerate}
\end{proof}

Equations stated in Lemma \ref{lemma:brk} alone determine the $b(r,k)$ function. 
\begin{lemma}[Uniqueness of coefficients]
System of equations \eqref{eq:b_rkis1} and \eqref{eq:0.5b+0.5b} has a unique solution, making $b_{r,k}$ a well-defined function $b(r,k)$.
\end{lemma}

Let us prove this by rewriting the equations into a matrix and showing nonzero determinant.
\begin{proof}

Under the condition \(1 \le r \le k,\; k \in \mathbb{N}\), the system can be rewritten as:
\[
\begin{aligned}
    2b(r,k) - b(r+1,k) &= b(r,k-1),\\
    \sum_{j=1}^{k} b(j,k) &= 1.
\end{aligned}
\]

Expressing it in matrix form:
\[
\left(
\begin{NiceArray}{ccccc|c}
    2 & -1 & 0 & \Cdots & 0 & b(1,k-1) \\
    0 & 2 & -1 & \Cdots & 0 & b(2,k-1) \\
    \Vdots & \Vdots & \Vdots & \Ddots & \Vdots & \Vdots \\
    0 & 0 & \Cdots & 2 & -1 & b(k-1,k-1) \\
    1 & 1 & \Cdots & 1 & 1 & 1
\end{NiceArray}
\right)
\]

To compute the determinant, we perform a Laplace expansion along the last row.  
\paragraph{Intermediate step}
Add all previous rows to the last row and subtract this sum from the last row.  
This transforms the last row into:
\[
(-1,\; 0,\; 0,\; \dots,\; 0,\; 2),
\]
so the determinant becomes:
\[
\begin{vmatrix}
    2 & -1 & 0 & \cdots & 0 \\
    0 & 2 & -1 & \cdots & 0 \\
    0 & 0 & 2 & \cdots & 0 \\
    \vdots & \vdots & \vdots & \ddots & -1 \\
    -1 & 0 & 0 & \cdots & 2
\end{vmatrix} = 2^k-1.
\]

Since $k>0$ this expression is nonzero.
\end{proof}



\subsection{Relations}
We already know the properties satisfied by $b(r,k)$; now we still need to show the converse lemma, namely the conditions that $c(r,k)$ satisfies in terms of $b(r,k)$.

\begin{lemma}[Converse relation between $c(r,k)$ and $b(r,k)$]
For integers $k \ge 0$ and $0 \le r \le k$, the coefficients $c(r,k)$ satisfy:
\[
c(r,k) = \sum_{j=1}^{k} b(1,j) + \sum_{i=1}^{r} b(i,k).
\]
\end{lemma}

\begin{proof}
To prove this, we show that all the equations from \ref{theorem:3equations_of_crk} that uniqely define $c(r,k)$ hold.
    \begin{enumerate}
        \item $c(0,0)=0$:
For $k=r=0$ the equation gives
$$
c(0,0) = \sum_{j=1}^{0} b(1,j) + \sum_{i=1}^{0} b(i,k) = 0,
$$
so this equation holds.
        \item $c(k,k)-c(0,k) = 1$:
    For this we use the already-proven equation \eqref{eq:b_rkis1}.
    \begin{multline*}
        c(k,k)-c(0,k)=\\
        =\bigg(\sum_{j=1}^{k} b(1,j) + \sum_{i=1}^{k} b(i,k)\bigg)
        - \bigg(\sum_{j=1}^{k} b(1,j) + \sum_{i=0}^{0}b(i,k)\bigg)=\\=
        \sum_{i=1}^{k} b(i,k)=1
    \end{multline*}
    
        \item $2c(r,k)=c(r+1,k)+c(r,k-1)$:
    We start from \eqref{eq:0.5b+0.5b} and substitue with our lemma's equation:
    \begin{multline*}
         \frac{1}{2}c(r+1,k)+c(r,k-1) =\\
        =\frac{1}{2}(\sum_{i=1}^{k}b(1,i)+\sum_{j=1}^{r+1}b(j,k)+\sum_{i=1}^{k-1}b(1,i)+\sum_{j=1}^{r}b(j,k-1))=\\
        = \frac{1}{2}(\sum_{i=1}^{k-1}2b(1,i)+b(1,k)+b(1,k)+\sum_{j=1}^{r}b(j+1,k)+\sum_{j=1}^{r}b(j,k-1))=\\
        = \frac{1}{2}(\sum_{i=1}^{k-1}2b(1,i)+b(1,k)+b(1,k)+\sum_{j=1}^{r}(b(j+1,k)+b(j,k-1)))=\\
        = \frac{1}{2}(\sum_{i=1}^{k-1}2b(1,i)+b(1,k)+b(1,k)+\sum_{j=1}^{r}2b(r,k))=\\
        =\frac{1}{2}(\sum_{i=1}^{k-1}2b(1,i)+2b(1,k)+\sum_{j=1}^{r}2b(r,k))=\\
        =\sum_{i=1}^{k-1}b(1,i)+b(1,k)+\sum_{j=1}^{r}b(r,k)=\\
        =\sum_{i=1}^{k}b(1,i)+\sum_{j=1}^{r}b(r,k)=c(r,k)
    \end{multline*}
    \end{enumerate}
\end{proof}

\subsection{using Prk to construct Brk}
\textcolor{red}{TODO:}
In the following, we shall show that $b_{r,k}$ can be expressed by the similar inner product as in the case of $c_{r,k}$. For this, we need to define a new multiplication vector $v_b$.

\begin{definition}[Multiplication vector $v_b$]
Define the vector
\[
v_b = \bigl(\, 1,\,-\tfrac{1}{3},\,\tfrac{1}{7},\,\ldots,\,\tfrac{(-1)^{i+1}}{2^i-1},\,\ldots\bigr).
\]
\end{definition}

\begin{lemma}
    Multiplication vector $v_b$ is a part of $\ell^{2}$.
\end{lemma}

\begin{proof}
We recall again the condition \eqref{eq:l2iflesstheninfty} for item to be in $\ell^{2}$. The proof holds the same as for $v_c$, since we have only prepended the vector with zero which did not change the infinite sum.
\end{proof}

In what follows, we introduce a inner product for calcuating $b(r,k)$.
\begin{lemma}
    For integers \(k \ge 0\) and \(1 \le r \le k\) we say
    \begin{align}
        b(r,k) = \langle v_b,P_{r-1,k-1}\rangle
    \end{align}
\end{lemma}

We shall prove this by showing that system of equations for $b(r,k)$ hold.
\begin{proof} In this proof we shall prove that equations \eqref{eq:b_rkis1} and \eqref{eq:0.5b+0.5b} hold.
\begin{enumerate}
    \item We start with the first equation, $\sum_{j=1}^{k} b(j,k) = 1.$

    \[
\begin{array}{c|cccc}
P(r,k) & \alpha_0 & \alpha_1 & \alpha_2 & \alpha_3 \\
\hline
(0,2) & 1 & 2 & 1 & 0 \\
(1,2) & 1 & 3 & 2 & 0 \\
(2,2) & 1 & 4 & 4 & 0 \\
\end{array}
\]

\[
\begin{aligned}
\langle v_b, P_{0,2}\rangle &= 1 \cdot 1 + \Bigl(-\tfrac{1}{3}\Bigr)\cdot 2 + \Bigl(\tfrac{1}{7}\Bigr)\cdot 1
= 1 - \tfrac{2}{3} + \tfrac{1}{7}
= \tfrac{10}{21},\\[6pt]
\langle v_b, P_{1,2}\rangle &= 1 \cdot 1 + \Bigl(-\tfrac{1}{3}\Bigr)\cdot 3 + \Bigl(\tfrac{1}{7}\Bigr)\cdot 2
= 1 - 1 + \tfrac{2}{7}
= \tfrac{2}{7},\\[6pt]
\langle v_b, P_{2,2}\rangle &= 1 \cdot 1 + \Bigl(-\tfrac{1}{3}\Bigr)\cdot 4 + \Bigl(\tfrac{1}{7}\Bigr)\cdot 4
= 1 - \tfrac{4}{3} + \tfrac{4}{7}
= \tfrac{5}{21},
\end{aligned}
\] 
yielding

\[
\sum_{j=1}^{3} b(j,k) = \langle v_b, P_{0,2}\rangle + \langle v_b, P_{1,2}\rangle + \langle v_b, P_{2,2}\rangle
= \frac{21}{21} = 1.
\]

We claim that for every integer \(k \ge 0\),


For \(r-1 = j-1\) and \(k-1\) fixed, the coefficient of \(x^m\) in \(P_{j-1,k-1}\) is
\[
\alpha_m(j-1,k-1) = \sum_{p+q=m} \binom{j-1}{p} 2^p \binom{k-j}{q}.
\]

Thus
\[
b(j,k) = \sum_{m=1}^{k-1} \alpha_m(j-1,k-1)\,\frac{(-1)^m}{2^m-1}.
\]

Summing over \(j=1,\dots,k\) gives
\[
\sum_{j=1}^{k} b(j,k)
= \sum_{m=1}^{k-1} \frac{(-1)^m}{2^m-1} \sum_{j=1}^{k} \alpha_m(j-1,k-1).
\]

But
\[
\sum_{j=1}^{k} \alpha_m(j-1,k-1)
= \sum_{j=1}^{k} \sum_{p+q=m} \binom{j-1}{p} 2^p \binom{k-j}{q}.
\]

Reindexing and using the hockey-stick identity, this collapses to
\[
\sum_{p+q=m} 2^p \binom{k}{p+q+1} = 2^m \binom{k}{m+1}.
\]

Therefore
\[
\sum_{j=1}^{k} b(j,k)
= \sum_{m=1}^{k-1} \binom{k}{m+1} 2^m \cdot \frac{(-1)^m}{2^m-1}.
\]

Now observe that
\[
\frac{2^m}{2^m-1} - \frac{1}{2^m-1} = 1,
\]
so by grouping terms as in the proof for \(c(r,k)\), we get
\[
\sum_{m=1}^{k} \binom{k}{m} (-1)^{m+1} = 1,
\]
by the binomial identity \(\sum_{m=0}^{k} \binom{k}{m} (-1)^m = 0\).

Hence
\[
\sum_{j=1}^{k} b(j,k) = 1.
\]



\end{enumerate}
\end{proof}


\subsection{Approximation}

We start with an approximation of $b_{r,k}$ like:
$$
b_{rk}\approx\frac{1}{H_{2k-2}-H_{k-2}}\cdot\frac{1}{r+k-2}
$$
First being well-known function to approximate, yielding
$$
b_{rk}\approx\frac{1}{ln(2)}\cdot\frac{1}{r+k-2}
$$

We substitute this approximation into all the lemmas equations, yelding for the first equation
$$
\sum_{i=1}^{k}b_{ik} \approx\frac{1}{ln(2)}(\frac{1}{k-1}+\frac{1}{k}+\frac{1}{k+1}+\cdots+\frac{1}{2k-2})\approx\frac{H_{2k-2}-H_{k-2}}{ln(2)}\approx \frac{ln(2)}{ln(2)} \approx 1.
$$
this is consistent with our assumption.

Substituting into the second equation yields
\begin{align*}
\frac{1}{2}b_{r+1k}+\frac{1}{2}b_{rk-1}&\approx\frac{1}{ln2}\frac{1}{2}(\frac{1}{r+k-3}+\frac{1}{r+k-1})\approx\\
&\approx\frac{1}{ln2}\frac{1}{2}\frac{r+k-1+r+k-3}{(r+k-3)(r+k-1)}\approx\frac{1}{ln2}\frac{r+k-2}{(r+k-3)(r+k-1)}.
\end{align*}


We check whether this result provides a sufficiently good approximation to the previously obtained value ($b_{rk}=\frac{1}{ln(2)}\cdot\frac{1}{r+k-2}$).

We label the functions:
$$
f(r,k) = \frac{1}{ln(2)}\cdot\frac{1}{r+k-2}
$$
and
$$
g(r,k)=\frac{1}{ln2}\frac{r+k-2}{(r+k-3)(r+k-1)}.
$$

\subsubsection{Theory}
\begin{definition}[Order of Magnitude, p.~19]
It is said that $f(\varepsilon) = O(q(\varepsilon))$ for $\varepsilon \to 0$, if
\[
\lim_{\varepsilon \to 0} \frac{f(\varepsilon)}{q(\varepsilon)} = A, \quad 0 < |A| < \infty.
\]
\end{definition}

In addition, it is said that the functions $f(\varepsilon)$ and $q(\varepsilon)$ have the same \emph{order of magnitude}. 
strana 19 v Gao:
\url{https://utbcz-my.sharepoint.com/:b:/g/personal/a_ulrich_utb_cz/IQCowD5Uz9tnQ4FZdzpTsfLLAYpgJpNYeJcZxR5YsaERZTI?e=BlmlFg}.


Furthermore, de Bruijn mentions in Chapter~1.4 (\emph{Asymptotic equivalence}, p.~11) that:

\begin{quote}
We say that $f(x)$ and $g(x)$ are asymptotically equivalent as $x \to \infty$, if the quotient $f(x)/g(x)$ tends to unity. Our notation is
\[
f(x) \sim g(x) \qquad (x \to \infty).
\]
\end{quote}

Alternatively, this can be expressed as:
\[
\lim_{x \to \infty} \frac{f(x)}{g(x)} = 1.
\]


This notation will also be used for all other ways of passing to a limit.


\begin{align*}
&\lim_{k\rightarrow\infty}\frac{f}{g} =\lim_{k\rightarrow\infty} \frac{\frac{1}{ln(2)}\cdot\frac{1}{r+k-2}}{\frac{1}{ln2}\frac{r+k-2}{(r+k-3)(r+k-1)}}=\\
&=\lim_{k\rightarrow\infty}\frac{(r+k-3)(r+k-1)}{(r+k-2)^2}=[\frac{(r^2+rk-r+kr+k^2-k-3r-3k+3)}{(r+k)^2-2(r+k)2+4}]=\\
&=[\frac{r^2+rk-r+kr+k^2-k-3r-3k+3}{r^2+2rk+k^2-4r-4k+4}=\lim_{k\rightarrow\infty}[\frac{k^2(1+...)}{k^2(1+...)}]=1    
\end{align*}

Thus, we have shown that $f(r,k)$ and $g(r,k)$ are asymptotically equivalent as $k \to \infty$, i.e.,
\[
f(r,k) \sim g(r,k) \qquad (k \to \infty),
\]
in the sense of de Bruijn~\cite[Ch.~1.4]{debruijn1981asymptotic}, since their quotient tends to unity.

So we have shown that the functions $f(r,k)$ and $g(r,k)$ have the same order of magnitude.

To confirm that also the actual values agree (at least up to a certain order \( n \)), we refer to Bender's concept concerning the comparison of two functions.

\paragraph{Asymptotic Power Series (Bender \& Orszag, p.~89,\cite{bender2013advanced})}
\url{https://utbcz-my.sharepoint.com/:b:/g/personal/a_ulrich_utb_cz/IQBKSQxcCYLyT7T8GdrWJyPHAVaVW0szQgG_BqGHQRLsQ10?e=7FC76l}
In Chapter 3, Bender and Orszag define an asymptotic power series as follows:
\begin{quote}
The power series $\sum_{n=0}^\infty a_n (x-x_0)^n$ is said to be asymptotic to the function $y(x)$ as $x \to x_0$ if
\[
y(x) - \sum_{n=0}^N a_n (x-x_0)^n \ll (x-x_0)^N \qquad (x \to x_0)
\]
for every $N$.
\end{quote}
\textit{In words: The remainder after $N$ terms is much smaller than the last retained term as $x \to x_0$.}

They also give an equivalent formulation:
\begin{quote}
\[
y(x) - \sum_{n=0}^M a_n (x-x_0)^n \sim a_M (x-x_0)^M \qquad (x \to x_0)
\]
\end{quote}
\textit{In words: If you subtract the first $M$ terms, the remainder is of the same order as the next term.}

In particular, if two functions $f$ and $g$ have asymptotic expansions that agree up to order $n$, then their difference satisfies $f(x) - g(x) = O((x-x_0)^{n+1})$ as $x \to x_0$.

Thus, if we wish to demonstrate that two functions agree up to order $n$, it suffices to show that their difference is $O((x-x_0)^{n+1})$ as $x \to x_0$.

\subsubsection{Taylor series and limit approximation of f and g}
First, we start with previously defined approximations $f(r,k)$ and $g(r,k)$.
Since the following approximation methods are better used with one variable, we substitute:
$$
x :=r+k-2,
$$
yielding
\begin{align*}
    F(x) &= \frac{1}{ln(2)}\frac{1}{x}\\
    G(x) &= \frac{1}{ln(2)}\frac{x}{x^2-1}
\end{align*}

Then we subtract these to show the the maximum error that can occur between these two approximations.
$$
R(x)=G(x)-F(x)=\frac{1}{ln(2)}(\frac{x}{x^2-1}-\frac{1}{x})=\frac{1}{ln(2)}\frac{1}{x(x^2-1)}
$$

We substitute $x\rightarrow t$, yielding

\begin{align*}
    R(t) = G(t) - F(t)= \frac{1}{ln(2)}\biggr(\frac{1}{\frac{1}{t}(\frac{1}{t^2}-1)}\biggl)= \frac{1}{ln(2)}\biggr(\frac{t^3}{1-t^2}\biggl)
\end{align*}
Now we do Taylor expansion up to third derivative, yielding:
\begin{align*}
T(t)&=0+0t+0t^2+\frac{6t^3}{3!}+O(t^4)\\    
T(x)&=0+0\frac{1}{t}+0\frac{1}{x^2}+\frac{6}{3!}\frac{1}{x^3}+O(\frac{1}{x^4})
\end{align*}
Hence these functions agree up to order of $2$.

We try different approach now (Spivak, page 418).
\begin{quote}
Following Spivak~\cite{SpivakMichael1994C}, two functions \( f \) and \( g \) are said to be \emph{equal up to order \( n \) at \( a \)} if
\[
\lim_{x \to a} \frac{f(x) - g(x)}{(x - a)^n} = 0.
\]
\end{quote}

Using this approach with our functions $G(t)$ and $F(t)$ yields:

\begin{align*}
    2.)\lim_{x\rightarrow0^+}\frac{G(t)-F(t)}{t^2} &=0\\
    3.)\lim_{x\rightarrow0^+}\frac{G(t)-F(t)}{t^3} &= \lim_{x\rightarrow0^+}\frac{t^3}{t^3(1-t^2)}=1
\end{align*}
Since the last $n$ for which the limit was zero was $n = 2$, the functions are equal up to order $2$ at $0$.



\section{jak se lisi vysledky crk s missing a ck bez missing}
- plus mozna i dukaz opet ze to opravdu bude fungovat vzdy

\section{priklad pro dusana}


\bibliographystyle{alpha}
\bibliography{bibli}

\end{document}
